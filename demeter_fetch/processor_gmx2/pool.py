import ast
import datetime
from typing import Dict, List

import numpy as np
import pandas as pd
from tqdm import tqdm

from demeter_fetch import NodeNames, GmxV2Config
from demeter_fetch.common import DailyNode, DailyParam, get_depend_name
from .gmx2_utils import GMX_FLOAT_DECIMAL

pool_file_columns = [
    "timestamp",  # ðŸ’š
    "block_number",  # ðŸ’š
    "transaction_Hash",  # ðŸ’š
    "tx_type",  # ðŸ’š
    "longAmount",  # ðŸ’š  #:  event MarketPoolValueInfo
    "shortAmount",  # ðŸ’š  #:  event MarketPoolValueInfo
    "virtualSwapInventoryLong",  # ðŸ’š   deposit,VirtualSwapInventoryUpdated, calculate priceImpact of deposit
    "virtualSwapInventoryShort",  # ðŸ’š deposit,VirtualSwapInventoryUpdated
    "poolValue",  # ðŸ’š  deposit, event MarketPoolValueInfo,
    "marketTokensSupply",  # ðŸ’š  deposit, event MarketPoolValueInfo
    "impactPoolAmount",  # ðŸ’š  deposit, event MarketPoolValueInfo/PositionImpactPoolAmountUpdated
    "totalBorrowingFees",  # ðŸ’š
    "longPnl",  # ðŸ’š from MarketPoolValueInfo, used to calculate poolvalue
    "shortPnl",  # ðŸ’š from MarketPoolValueInfo
    "netPnl",  # ðŸ’š from MarketPoolValueInfo
    "openInterestLongIsLong",  # ðŸ’š  event OpenInterestUpdated, to calculate pnl,
    "openInterestLongNotLong",  # ðŸ’š
    "openInterestShortIsLong",  # ðŸ’š
    "openInterestShortNotLong",  # ðŸ’š
    "openInterestInTokensLongIsLong",  # ðŸ’š   event : OpenInterestInTokensUpdated, to calculate pnl,
    "openInterestInTokensLongNotLong",  # ðŸ’š
    "openInterestInTokensShortIsLong",  # ðŸ’š
    "openInterestInTokensShortNotLong",  # ðŸ’š
]


def find_log(name: str, tx_data: pd.DataFrame) -> pd.Series | None:
    # Grok give me this magic line. it believes it is the fastest to find first record
    locate = (tx_data["event_name"] == name).idxmax()
    if locate > tx_data.index[0]:
        return tx_data.loc[locate]
    if tx_data.iloc[0]["event_name"] == name:
        return tx_data.iloc[0]
    else:
        return None


def _add_pool_value_prop(pool_snapshot: Dict, pool_config, tx_data):
    log = find_log("MarketPoolValueInfo", tx_data)
    if log is not None:
        log_data = ast.literal_eval(log["data"])
        pool_snapshot["longAmount"] = log_data["longTokenAmount"] / 10**pool_config.long_token.decimal
        pool_snapshot["shortAmount"] = log_data["shortTokenAmount"] / 10**pool_config.short_token.decimal
        pool_snapshot["poolValue"] = log_data["poolValue"] / GMX_FLOAT_DECIMAL
        pool_snapshot["marketTokensSupply"] = log_data["marketTokensSupply"] / 10**18
        pool_snapshot["impactPoolAmount"] = log_data["impactPoolAmount"] / 10**pool_config.index_token.decimal
        pool_snapshot["totalBorrowingFees"] = log_data["totalBorrowingFees"] / GMX_FLOAT_DECIMAL
        pool_snapshot["longPnl"] = log_data["longPnl"] / GMX_FLOAT_DECIMAL
        pool_snapshot["shortPnl"] = log_data["shortPnl"] / GMX_FLOAT_DECIMAL
        pool_snapshot["netPnl"] = log_data["netPnl"] / GMX_FLOAT_DECIMAL


def _add_pool_value_prop_last(pool_config, tx_data, last_snapshot):
    # for the last row of the day
    log = find_log("MarketPoolValueUpdated", tx_data)
    if log is not None:
        log_data = ast.literal_eval(log["data"])
        last_snapshot["longAmount"] = log_data["longTokenAmount"] / 10**pool_config.long_token.decimal
        last_snapshot["shortAmount"] = log_data["shortTokenAmount"] / 10**pool_config.short_token.decimal
        last_snapshot["marketTokensSupply"] = log_data["marketTokensSupply"] / 10**18
        last_snapshot["impactPoolAmount"] = log_data["impactPoolAmount"] / 10**pool_config.index_token.decimal
        last_snapshot["totalBorrowingFees"] = log_data["totalBorrowingFees"] / GMX_FLOAT_DECIMAL


def _add_swap_inventory(pool_snapshot: Dict, pool_config, tx_data, last_snapshot):
    log = find_log("VirtualSwapInventoryUpdated", tx_data)
    if log is not None:
        log_data = ast.literal_eval(log["data"])
        old_val = log_data["nextValue"] - log_data["delta"]
        if log_data["isLongToken"]:
            pool_snapshot["virtualSwapInventoryLong"] = old_val / 10**pool_config.long_token.decimal
            last_snapshot["virtualSwapInventoryLong"] = log_data["nextValue"] / 10**pool_config.long_token.decimal
        else:
            pool_snapshot["virtualSwapInventoryShort"] = old_val / 10**pool_config.short_token.decimal
            last_snapshot["virtualSwapInventoryShort"] = log_data["nextValue"] / 10**pool_config.short_token.decimal


def _add_pool_amount(pool_snapshot: Dict, pool_config, tx_data, last_snapshot):
    log = find_log("PoolAmountUpdated", tx_data)
    if log is not None:
        log_data = ast.literal_eval(log["data"])
        old_val = log_data["nextValue"] - log_data["delta"]
        if log_data["token"].lower() == pool_config.long_token.address:
            pool_snapshot["longAmount"] = old_val / 10**pool_config.long_token.decimal
            last_snapshot["longAmount"] = log_data["nextValue"] / 10**pool_config.long_token.decimal
        else:
            pool_snapshot["shortAmount"] = old_val / 10**pool_config.short_token.decimal
            last_snapshot["shortAmount"] = log_data["nextValue"] / 10**pool_config.short_token.decimal


def _add_position_impact_pool_amount(pool_snapshot: Dict, pool_config, tx_data, last_snapshot):
    log = find_log("PositionImpactPoolAmountUpdated", tx_data)
    if log is not None:
        log_data = ast.literal_eval(log["data"])
        old_val = log_data["nextValue"] - log_data["delta"]
        pool_snapshot["impactPoolAmount"] = old_val / 10**pool_config.index_token.decimal
        last_snapshot["impactPoolAmount"] = log_data["nextValue"] / 10**pool_config.index_token.decimal


def _add_open_interest(pool_snapshot: Dict, pool_config: GmxV2Config, tx_data, last_snapshot):
    log = find_log("OpenInterestUpdated", tx_data)
    if log is not None:
        log_data = ast.literal_eval(log["data"])
        old_val = log_data["nextValue"] - log_data["delta"]
        if pool_config.long_token.address == log_data["collateralToken"]:
            if log_data["isLong"]:
                pool_snapshot["openInterestLongIsLong"] = old_val / GMX_FLOAT_DECIMAL
                last_snapshot["openInterestLongIsLong"] = log_data["nextValue"] / GMX_FLOAT_DECIMAL
            else:
                pool_snapshot["openInterestLongNotLong"] = old_val / GMX_FLOAT_DECIMAL
                last_snapshot["openInterestLongNotLong"] = log_data["nextValue"] / GMX_FLOAT_DECIMAL
        elif pool_config.short_token.address == log_data["collateralToken"]:
            if log_data["isLong"]:
                pool_snapshot["openInterestShortIsLong"] = old_val / GMX_FLOAT_DECIMAL
                last_snapshot["openInterestShortIsLong"] = log_data["nextValue"] / GMX_FLOAT_DECIMAL
            else:
                pool_snapshot["openInterestShortNotLong"] = old_val / GMX_FLOAT_DECIMAL
                last_snapshot["openInterestShortNotLong"] = log_data["nextValue"] / GMX_FLOAT_DECIMAL
        else:
            raise RuntimeError("OpenInterestUpdated should have long or short token")


def _add_open_interest_in_tokens(pool_snapshot: Dict, pool_config: GmxV2Config, tx_data, last_snapshot):
    log = find_log("OpenInterestInTokensUpdated", tx_data)
    if log is not None:
        log_data = ast.literal_eval(log["data"])
        old_val = log_data["nextValue"] - log_data["delta"]
        if pool_config.long_token.address == log_data["collateralToken"]:
            if log_data["isLong"]:
                pool_snapshot["openInterestInTokensLongIsLong"] = old_val / 10**pool_config.index_token.decimal
                last_snapshot["openInterestInTokensLongIsLong"] = (
                    log_data["nextValue"] / 10**pool_config.index_token.decimal
                )
            else:
                pool_snapshot["openInterestInTokensLongNotLong"] = old_val / 10**pool_config.index_token.decimal
                last_snapshot["openInterestInTokensLongNotLong"] = (
                    log_data["nextValue"] / 10**pool_config.index_token.decimal
                )
        elif pool_config.short_token.address == log_data["collateralToken"]:
            if log_data["isLong"]:
                pool_snapshot["openInterestInTokensShortIsLong"] = old_val / 10**pool_config.index_token.decimal
                last_snapshot["openInterestInTokensShortIsLong"] = (
                    log_data["nextValue"] / 10**pool_config.index_token.decimal
                )
            else:
                pool_snapshot["openInterestInTokensShortNotLong"] = old_val / 10**pool_config.index_token.decimal
                last_snapshot["openInterestInTokensShortNotLong"] = (
                    log_data["nextValue"] / 10**pool_config.index_token.decimal
                )
        else:
            raise RuntimeError("OpenInterestInTokensUpdated should have long or short token")


class GmxV2PoolTx(DailyNode):
    """
    Pool state when a transaction occurs.
    """

    name = NodeNames.gmx2_pool

    def _get_file_name(self, param: DailyParam) -> str:
        return (
            f"{self.from_config.chain.name}-GmxV2-{self.from_config.gmx_v2_config.GM_address}-{param.day.strftime('%Y-%m-%d')}.pool"
            + self._get_file_ext()
        )

    @property
    def _parse_date_column(self) -> List[str]:
        return ["timestamp"]

    def _process_one_day(self, data: Dict[str, pd.DataFrame], day: datetime.date) -> pd.DataFrame:
        """
        You need to use the value at the start of each transaction to make minute-level data more accurate.
        For example, if a transaction occurs at 10:10:23, the final minute-level data will need the state at 10:10:00.
        At this point, the transaction hasnâ€™t happened yet, so you need to calculate the state before this transaction occurs.
        The data for 10:11:00, on the other hand, will be filled by subsequent transactions.
        This can cause an issue where the data at the end of the day is incorrect.
        For instance, if the last transaction of the day happens at 23:50:25, the data starting from 23:51:00 cannot
        simply use the state at 23:50:00, because the state has already been altered by the transaction in that minute.
        Therefore, you should set a last variable to record the final state and place it at the very last moment of the day.
        This way, a simple bfill() can be used to fill all the data accurately.
        :param data:
        :param day:
        :return:
        """
        tick_df = data[get_depend_name(NodeNames.gmx2_tick, self.id)]

        pool_config = self.config.from_config.gmx_v2_config

        tick_df["market"] = tick_df["market"].str.lower()
        tick_df = tick_df[tick_df["market"] == pool_config.GM_address.lower()]
        tick_df = tick_df[(tick_df["tx_type"] != "") & (~tick_df["tx_type"].isna())]
        tick_df = tick_df.reset_index(drop=True)
        txes = tick_df.groupby(["block_number", "tx_index"])

        row_list = []
        # for the last row of the day
        last_snapshot = {
            "timestamp": datetime.datetime.combine(day, datetime.time(23, 59, 59), tzinfo=datetime.timezone.utc)
        }
        # all take the first value(before this tx happend)
        with tqdm(total=len(txes), ncols=60, position=1, leave=False) as pbar:
            for (height, tx_index), tx_data in txes:
                pool_snapshot = {
                    "timestamp": tx_data.iloc[0]["block_timestamp"],
                    "block_number": height,
                    "transaction_Hash": tx_data.iloc[0]["transaction_hash"],
                    "tx_type": tx_data.iloc[0]["tx_type"],
                }

                _add_pool_value_prop(pool_snapshot, pool_config, tx_data)
                _add_pool_value_prop_last(pool_config, tx_data, last_snapshot)
                _add_pool_amount(pool_snapshot, pool_config, tx_data, last_snapshot)
                _add_swap_inventory(pool_snapshot, pool_config, tx_data, last_snapshot)
                _add_open_interest(pool_snapshot, pool_config, tx_data, last_snapshot)
                _add_open_interest_in_tokens(pool_snapshot, pool_config, tx_data, last_snapshot)
                _add_position_impact_pool_amount(pool_snapshot, pool_config, tx_data, last_snapshot)
                row_list.append(pool_snapshot)
                pbar.update()

        row_list.append(last_snapshot)
        df = pd.DataFrame(row_list)

        for column_name in pool_file_columns:
            if column_name not in df.columns:
                df[column_name] = np.nan
        df = df[pool_file_columns]
        return df
